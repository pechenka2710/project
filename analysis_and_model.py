import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve

def main():
    st.title("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª—å")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç (CSV)", type="csv")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º session_state –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–µ–π
    if 'models' not in st.session_state:
        st.session_state.models = {}
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False

    if uploaded_file is not None:
        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è, –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª
        if st.session_state.data_loaded:
            st.session_state.models = {}
            st.session_state.data_loaded = False

        data = pd.read_csv(uploaded_file)
        
        # ---- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ----
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (TWF, HDF, PWF, OSF, RNF)
        columns_to_drop = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']
        existing_columns = [col for col in columns_to_drop if col in data.columns]
        data = data.drop(columns=existing_columns)

        # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ 'Type'
        data['Type'] = LabelEncoder().fit_transform(data['Type'])

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        scaler = StandardScaler()
        numerical_features = [
            'Air temperature', 
            'Process temperature', 
            'Rotational speed', 
            'Torque', 
            'Tool wear'
        ]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
        missing_cols = [col for col in numerical_features if col not in data.columns]
        if missing_cols:
            st.error(f"–°—Ç–æ–ª–±—Ü—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç: {missing_cols}")
        else:
            data[numerical_features] = scaler.fit_transform(data[numerical_features])

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X = data.drop(columns=['Machine failure'])
        y = data['Machine failure']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        models = {
            "Logistic Regression": LogisticRegression(),
            "Random Forest": RandomForestClassifier(n_estimators=100),
            "XGBoost": XGBClassifier()
        }

        for name, model in models.items():
            model.fit(X_train, y_train)
            st.session_state.models[name] = model  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ session_state

        st.session_state.data_loaded = True
        st.success("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")

    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if st.session_state.data_loaded:
        st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è")
        for name, model in st.session_state.models.items():
            y_pred = model.predict(X_test)
            st.subheader(f"–ú–æ–¥–µ–ª—å: {name}")
            st.write(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
            
            # Confusion Matrix
            fig, ax = plt.subplots()
            sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', ax=ax)
            st.pyplot(fig)

        # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        st.header("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
        with st.form("prediction_form"):
            air_temp = st.number_input("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤–æ–∑–¥—É—Ö–∞", value=300.0)
            process_temp = st.number_input("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞", value=310.0)
            rotational_speed = st.number_input("–°–∫–æ—Ä–æ—Å—Ç—å –≤—Ä–∞—â–µ–Ω–∏—è", value=1500)
            torque = st.number_input("–ö—Ä—É—Ç—è—â–∏–π –º–æ–º–µ–Ω—Ç", value=40.0)
            tool_wear = st.number_input("–ò–∑–Ω–æ—Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞", value=100)
            product_type = st.selectbox("–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ç–∞", ["L", "M", "H"])
            
            if st.form_submit_button("–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å"):
                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
                type_encoded = 0 if product_type == "L" else 1 if product_type == "M" else 2
                
                input_data = pd.DataFrame({
                    'Type': [type_encoded],
                    'Air temperature': [air_temp],
                    'Process temperature': [process_temp],
                    'Rotational speed': [rotational_speed],
                    'Torque': [torque],
                    'Tool wear': [tool_wear]
                })
                
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                input_data[numerical_features] = scaler.transform(input_data[numerical_features])
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                model = st.session_state.models["Random Forest"]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                prediction = model.predict(input_data)[0]
                probability = model.predict_proba(input_data)[0][1]
                
                st.success(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {'–û—Ç–∫–∞–∑ üî¥' if prediction == 1 else '–ù–µ—Ç –æ—Ç–∫–∞–∑–∞ üü¢'}")
                st.write(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç–∫–∞–∑–∞: {probability:.2%}")

    else:
        st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —á–µ—Ä–µ–∑ —Ñ–æ—Ä–º—É –≤—ã—à–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑.")

if __name__ == "__main__":
    main()